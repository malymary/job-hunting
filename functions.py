import time
import json
import requests
import tqdm
import pandas as pd
from collections import Counter
from IPython.display import display, clear_output
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pandas as pd
import config

'''Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ JSON-Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² Ñ€Ğ°Ğ±Ğ¾Ñ‡ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ'''
'''Save JSON file to the working directory'''

def dump_json(obj, filename):
        with open(filename, 'w', encoding='UTF-8') as f: 
            json.dump(obj, f, ensure_ascii=False, indent=4)

            
'''âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨'''          
            
'''Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ñ ÑĞ°Ğ¹Ñ‚Ğ° hh.ru'''
'''Parse vacancies at hh.ru'''

def get_vacancies(page = config.PAGE,
    per_page = config.PER_PAGE,
    period = config.PERIOD,
    text = config.TEXT,
    experience = config.EXPERIENCE,
    employment= config.EMPLOYMENT,
    schedule = config.SCHEDULE,
    area= config.AREA,
    industry = config.INDUSTRY,
    salary = config.SALARY,
    only_with_salary = config.ONLY_WITH_SALARY):

    params = {
        'page': page,
        'per_page': per_page,
        'period': period,
        'text': text,
        'experience': experience,
        'employment': employment,
        'schedule': schedule,
        'area': area,
        'industry': industry,
        'salary': salary,
        'only_with_salary': only_with_salary,
        }
    
    res = requests.get('https://api.hh.ru/vacancies', params=params)
    if not res.ok:
        print('Error:', res)
    vacancies = res.json()['items']
    pages = res.json()['pages']

    for page in tqdm.trange(1, pages):
        params['page'] = page
        res = requests.get('https://api.hh.ru/vacancies', params=params)
        if res.ok:
            response_json = res.json()
            vacancies.extend(response_json['items'])
        else:
            print(res)
            
    # dump_json(vacancies, 'vacancies.json')
    return vacancies


'''âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨''' 

'''Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ° Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ (Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ½Ğ¾ 100 Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ Ğ² Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñƒ)'''
'''Get a new file with job descriptions (around 100 descriptions per min)'''

def get_full_descriptions(vacancies):
    vacancies_full = []
    for entry in tqdm.tqdm(vacancies):
        vacancy_id = entry['id']
        description = requests.get(f'https://api.hh.ru/vacancies/{vacancy_id}')
        vacancies_full.append(description.json())
        print(description.json())
        time.sleep(0.2)
        clear_output()
    dump_json(vacancies_full, 'vacancies_full.json')
    return vacancies_full


'''âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨''' 

'''Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ° c Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹ c Ğ“ÑƒĞ³Ğ» Ğ”Ğ¸ÑĞºĞ°'''
'''Download an existing file with job descriptions from Google Drive'''

def load_from_gdrive(file_id, filename):
    url = f'https://drive.google.com/uc?export=view&id={file_id}'
    res = requests.get(url)
    vacancies_full = res.json()
    dump_json(vacancies_full, filename)
    return vacancies_full


'''âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨''' 

'''Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ³Ğ¾ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ° c Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ²Ğ°ĞºĞ°Ğ½ÑĞ¸Ğ¹'''
'''Open an existing local file with job descriptions'''

def load_from_device(file_path):
    with open(f'{file_path}', encoding='utf8') as f: vacancies_full = json.load(f)
    return vacancies_full


'''âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨''' 

'''Ğ¡Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ², Ğ¾Ñ‚ÑĞ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾ Ğ¿Ğ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ğ¾ÑÑ‚Ğ¸'''
'''Make a list of key skills sorted by frequency'''

def sort_skills_by_freq(vacancies_full):
    all_skills = []
    for vacancy in vacancies_full:
        if vacancy['key_skills'] is None:
            continue
        else:
            for skill in vacancy['key_skills']:
                all_skills.append(skill['name'])
    frequencies = Counter(all_skills)

    freq_table = pd.DataFrame.from_dict(frequencies, orient='index', columns=['Frequency'])
    freq_table = freq_table.sort_values('Frequency', ascending=False)
    pd.set_option('display.max_rows', None)
    print(freq_table)
    
    return frequencies
    

'''âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨ğŸ³âœ¨ğŸ¬âœ¨ğŸŸâœ¨ğŸ âœ¨''' 

'''ĞÑ‚Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¸Ñ‚ÑŒ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ²Ğ¾Ñ€Ğ´ĞºĞ»Ğ°ÑƒĞ´ Ñ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ²Ñ‹ĞºĞ°Ğ¼Ğ¸'''
'''Display and save key skills as a wordcloud'''

def make_cloud(frequencies):
    print(f'Ğ¢Ğ¾Ğ¿ Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ² Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ {config.TEXT}:')
    cloud = WordCloud(background_color='black', width=800, height=600, color_func=lambda *args, **kwargs: "white")
    my_image = cloud.generate_from_frequencies(frequencies=frequencies).to_image()
    display(my_image)
    my_image.save(f'top_skill_wordcloud.png')